% \documentclass[CEJM,DVI]{cej} % use DVI command to enable LaTeX driver
\documentclass[CEJM,PDF]{cej} % use PDF command to enable PDFLaTeX driver
\usepackage{layout}
\usepackage{booktabs}
\usepackage{latexsym}
\renewcommand*\rmdefault{ppl}
\graphicspath{ {images/} }


\title{Predicting The Best Starting Price for Ebay Auctions}

\articletype{Course Project Milestone 2: Prediction on Item sale} % Research Article, Review Article, Communication, Erratum




\author{Jiacheng~Liao\inst{1},
        Yi~Wan\inst{1},
        Shuang~Zhou\inst{1},
        Zhaoyin~Zhu\inst{2}
       }

%\shortauthor{F. Author, S. Author}

\institute{\inst{1}
           Department of Computer Science, New York University, New York, NY 10012, USA
           \inst{2}
           Division of Biostatistics, NYU School of Medicine, New York, NY 10016, USA
          }

\abstract{Online auctions are one of the most popular methods to buy and sell items on the internet. With more than 100 million active users globally, eBay is the world’s largest online marketplace, where anyone can buy and sell anything. In order to successfully selling products on ebay, a reasonable starting price does not only determine whether the product will be sold or not but also affects the profit you can make from the transaction. In this project, we use the historical auction data collected from eBay from April 2013 to the first week of May 2013 which contains information about 296,048 successful and unsuccessful auctions. Different statistical models and machine learning algorithms will be utilized to study online auction patterns and predict the starting price that maximizes profits. Furthermore, we will compare the performance of different methods and summarize the pros and cons in different situations.
}

\keywords{Ebay Auction \*\ Predictive Analytics \*\ Data Mining}

%\msc{XXXXX, YYYYY}

\begin{document}
\maketitle
%\baselinestretch{2}
\section{Introduction (Data and Business Understanding) }

EBay is the world’s largest marketplace for sports autographs, the vast majority of the site’s membership uses it to buy and/or sell items via auction format. The ability to provide a method to estimate auction sale prices is desirable to this community. Members of most communities related to collectibles have reported they most often try to predict how much an auction would sell for by performing a search for item and manually calculating the average sales price. In this project, our first objective is to determine whether an auction listing will result in a sale. In addtion, we aim to predict the final sales price as well as the best starting price using data mining techniques.


\section{Data Preparation}

Data Preparation is an crucial and time-consuming part of our data mining project. It involves selecting data to include, cleaning data to improve data quality, constructing new data that may be required, integrating multiple data sets, and formatting data. We first preprocessed the downloaded data sets using shell scripts. To gain more experience on feature selection, we have performed the selection procedure on all three tools used in the class, RapidMiner, Weka and R. With different algorithms and parameters, we get slightly different but generally consistent results. 

\subsection*{Data Preprocessing}
Before any data can be used for later feature reduction and selection, we preprocessed our data sets. Here the tool we use is shell scripts. Initially, the raw data consists of training sets and test sets. Since we intend to do cross-validation on the whole data set, we merge all the separate data sets as one complete sets. Then we carefully go through all the data attributes and deleted all that obviously contain meaningless or irrelevant information to our analysis, such as ebayID, sellerName, etc. In addition, some attributes with ambiguous meanings are also discarded. 


\subsection{Feature Selection Using Weka}
First, we perform feature selection in Weka. To enable Weka to better handle the data, the first step is establishing a nominal class label. Below is a snapshot of the method we use here to discretize the class field here, which is originally a numeric type with value 0 and 1.

{\centering
    \vspace{3 mm}
    \includegraphics[scale=0.4]{weka-discretize_label_column.png}
    \par
}


Two algorithms are used in Weka: Information Gain and Feature Subset Selection. We first used Information Gain Algortihm and the result is as below. According to the information gain results we have, if we set the entropy threshold to 0.95, we will need the top 8 features.

{\centering
    \vspace{3 mm}
    \includegraphics[scale=0.6]{weka-InfoGain.png}
    \par
}

Using the number of features obtained above, we set the number of features to 8 and try feature subset selection. We start with empty subset, and we use CfsSubsetEval as the evaluation of each subset, and we use GreedyStepWise search method, which basically select the best next feature based on current subset. Here is the result we get.

{\centering
    \vspace{3 mm}
    \includegraphics[scale=0.6]{weka-FilteredSubsetWithGreedyStepwise.png}
    \par
}


\subsection{Feature Selection Using R}
The caret R package provides tools automatically report on the relevance and importance of attributes in your data and even select the most important features for you. Here we perform three different feature selection method on our dataset, namely entropy based filter, Chi-square based filter and Correlation based filter. We apply all three filters to get a better sense of what attributes are more important, and we have the results below.\\
\begin{center}
\includegraphics[scale=0.5]{entropy.png}\\
\mbox{}\\
\includegraphics[scale=0.5]{chi-square.png}\\
\mbox{}\\
\includegraphics[scale=0.5]{correlation.png}\\
\end{center}
As a result, we summarize all the three different methods and compute average rank for each attribute. The result is presented in table \ref{r-rank}.


\begin{table}[h]
\centering
\caption{Feature Selection Using R Result}
\label{r-rank}
\begin{tabular}{@{}ccccc@{}}
\toprule
Attribute Name         & Entropy based filter & Chi-square based filter & Correlation based filter & Average Rank \\ \midrule
SellerClosePercent     & 2                    & 2                       & 1                        & 1.7     \\
AvgPrice               & 1                    & 1                       & 6                        & 2.7     \\
AuctionMedianPrice     & 3                    & 3                       & 2                        & 2.7     \\
AuctionCount           & 4                    & 4                       & 5                        & 4.3     \\
AuctionSaleCount       & 7                    & 7                       & 4                        & 6.0     \\
StartingBid            & 8                    & 8                       & 3                        & 6.3     \\
StartingBidPercent     & 5                    & 5                       & 10                       & 6.7     \\
SellerAuctionCount     & 6                    & 6                       & 9                        & 7.0     \\
SellerItemAvg          & 9                    & 9                       & 8                        & 8.7     \\
ItemAuctionSellPercent & 10                   & 10                      & 7                        & 9.0     \\
IsHOF                  & 11                   & 11                      & 11                       & 11.0    \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Feature Selection Using RapidMiner}
First we choose a feature selection method from RapidMiner. Here we use Forward Selection. Forward selection operator selects the most relevant attributes of the given ExampleSet through a highly efficient implementation of the forward selection scheme. 

Forward selections uses wrapper method to select attributes. Basically, it starts with an empty attribute set. It them add one attribute to run the model and measures the performance. The process keep adding attributes to the model to see if there is performance gain. Depending on the parameter set, it will terminate until there is no performance improvement or no significant performance improvement. Here we also use cross-validation to measure the performance of the model as well as the current attributes set the operator.

For predicting the whether the given item can be sold or not, we use several classification algorithms, including: Naive Bayes, Decision Tree, Random Forest, Rule Induction, Neural net, Logistic Regression, Support Vector Machine. We will consider efficiency and prediction accuracy for each model to decide which one to adopt.

\subsubsection{Naive Bayes modeling}
{\centering
    A. The attribute weight
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-nb-aw.png}
    \par
}


{\centering
    B. The prediction model result and auc curve
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-nb-perf.png}
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-nb-auc.png}
    \par
}

\subsubsection{Decision Tree modeling}
{\centering
    A. The attribute weight
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-dec-aw.png}
    \par
}


{\centering
    B. The prediction model result and auc curve
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-dec-perf.png}
    \vspace{3 mm}
    \includegraphics[scale=0.6]{rm-dec-auc.png}
    \par
}

\subsection{Other Trials}
The other methods including Random Forest, Rule Induction, Neural net, Logistic Regression, Support Vector Machine takes a very long time to finish (more than one hour). Since the dataset we are using is not very large, we consider them not suitable for our problem.


\subsection{Final Feature Selection}
After integrating all results from 3 different tools, we narrowed the features down to these list of 8 features.
\begin{itemize}
\item StartingBidPercent
\item SellerClosePercent
\item StartingBid
\item AvgPrice
\item AuctionCount
\item AuctionSaleCount
\item SellerAuctionCount
\item AuctionMedianPrice
\end{itemize}
And from here on, unless specified otherwise, we are using the reduced dataset with only these features.


\section{Team Members Responsibilities and Plan for the Next Phase}

Right now, all group members are actively participate in the project. An approximate list of each team members' responsiblity is:
\begin{itemize}
\item Jiacheng Liao: data preprocessing, report write-up
\item Yi Wan: data preprocessing, feature selection in Rapidminer
\item Shuang Zhou: data preprocessing, feature selection in Weka
\item Zhaoyin Zhu: data preprocessing, feature selection in R
\end{itemize}

For the next phase,we intend to build different models to make predictions. We plan to apply various statistical machine learning model and use cross-validation to test each model. Also, we would study some economic aspects of the auction theory to help us build the model.



\section{Modeling}

Modeling involves selecting suitable modeling techniques, generating test designs to validate the model, building predictive models and assessing these models.\\
\\
A predictive model is a mathematical function that predicts the value of some output variables based on the mapping between input variables. Historical data is used to train the model to arrive at the most suitable modeling technique. For example, a predictive model might predict the risk of developing a certain disease based on patient details. Some commonly used modeling techniques are as follows: Regression analysis that analyzes the relationship between the response or dependent variable and a set of independent or predictor variables. Decision trees that help explore possible outcomes for various options. Cluster analysis that groups objects into clusters to look for patterns. Association techniques that discover relationships between variables in large databases.


\subsection{Modeling for Sale / No Sale}
In all three tools here, we tried to use different type of classification algorithms to decide whether items can be sold or not based on some information of item across Ebay.
\\
\subsubsection{Modeling in Weka}
In Weka, we tried to models, Naive-bayes model and Logistic Regression model. For NB, the model computed is as follow:
\begin{center}
\includegraphics[scale=0.5]{weka-nb-model1.png}\hspace*{3em}
\includegraphics[scale=0.5]{weka-nb-model2.png}
\end{center}
And also we evaluated the performance of this model:
\begin{center}
\includegraphics[scale=0.5]{weka-nb-result.png}
\end{center}
We decided to use F measure as the criteria to measure performances of each model. For NB model, the F measure is 0.639.\\
Now we go on and try another model, Logistic Regression. Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution. It fits very well in our situation, and it's a fast model to train and use. Below is the model we get:
\begin{center}
\includegraphics[scale=0.5]{weka-logi-model.png}
\end{center}
Again, we run 10 fold cross-validation on this model, and here is what we get:
\begin{center}
\includegraphics[scale=0.5]{weka-logi-result.png}
\end{center}
Obviously Logistic Regression model works much better than NB model, with a F measure of 0.837. Thus Logistic Regression will be our model of choice in Weka for this project.\\

\subsubsection{Modeling in RapidMiner}
In RapidMiner, models we tried include Naive Bayes, Random Forest, KNN, Decision Tree, Logistic Regression, Neural Network. We present Naive Bayse, Random Forest, and Decision Tree results here. We use cross validation for testing the performance. 
The figure below shows the performance for Naive Bayes.
\begin{center}
\includegraphics[scale=0.5]{01_bayse_performance.png}
\end{center} 
As we can see, too many instances that should belong to class ``0" are assigned to class ``1", actually 70 percent of all instances are assigned to class ``1" based on this model. Therefore, we can say that NB model is a little biased in this case and we shouldn't rely on the result.\\
\\
The second model we tried is Decision Tree classifier. A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. The decision tree algorithm comes with a ``depth" parameter and a evaluation algorithm. For the evaluation algorithm, we used Gain Ratio, and to obtain the best result, we tried multiple depths, and here is what we get.
\begin{center}
\textbf{Decision Tree performance with depth=5}\\
\includegraphics[scale=0.5]{rm_decition_tree_depth5.png}
\\
\textbf{Decision Tree performance with depth=10}\\
\includegraphics[scale=0.5]{rm_decision_tree_depth_50.png}
\\
\textbf{Decision Tree performance with depth=20}\\
\includegraphics[scale=0.5]{rm_decision_tree_depth_50.png}
\end{center} 
As we can see, the overall accuracy goes up a little when the depth increases from 5 to 10, but then the performance stays the same. Intuitively this makes sense because as the depth go up, it's more likely to find relations between each attribute and the label, but given there're only 8 features in total, the depth wouldn't matter too much after it exceeds the number of features.\\
\\
The third model we tried is Random-Forest classifier. Random forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests correct for decision trees' habit of overfitting to their training set.\\
\\
Random Forest algorithm needs a user specified number of trees to start with, and here we fix it to 10 in all experiments. Still we use Gain Ratio as the evaluation algorithm, here is what we get:
\begin{center}
\includegraphics[scale=0.5]{03_Randforest_performance.png}
\end{center} 
We can tell that the overall accuracy is slightly lower than Decision Tree algorithm, but as a property of Random Forest, it tends to get rid of overfitting behaviors of decision trees, so this is acceptable. And we will find out which one is more accurate when we apply them on unknown datasets.\\

\subsubsection{Modeling in R}
We ran Logistic Regression algorithm from the famous ``Generalized Linear Model" package in R.

\section{Evaluation (ToDo)}
Evaluation involves evaluating the results against the business success criteria defined at the beginning of the project.


\section{Deployment (ToDo)}
Deployment involves consolidating the findings, determining what might be deployed and planning the monitoring and maintenance required to keep the model relevant.

\section{Conclusion (ToDo)}
TODO


\section*{Acknowledgements}

The author(s) would like to thank some institutions for support and so on.


\begin{thebibliography}{9}

\bibitem{data-mining}Han, Jiawei, Micheline Kamber, and Jian Pei.\textit{ Data mining: concepts and techniques: concepts and techniques}. Elsevier, 2011.

\bibitem{mining-mass} Rajaraman, Anand, and Jeffrey D. Ullman. \textit{Mining of massive datasets}. Vol. 77. Cambridge: Cambridge University Press, 2012.

\bibitem{pre-dummy} Bari, Anasse, Mohamed Chaouchi, and Tommy Jung. \textit{Predictive analytics for dummies}. John Wiley \& Sons, 2014.	

\bibitem{lecture} Bari, Anasse. Predictive Analytics Course Lecture Notes. 2015 Fall.

\bibitem{r-feature}  Brownlee, Jason. Feature Selection with the Caret R Package. http://machinelearningmastery.com/feature-selection-with-the-caret-r-package/

\bibitem{ebay-auction} Grossman, Jay. Predicting eBay Auction Sales with Machine Learning.

Retrived from http://jaygrossman.com/post/2013/06/10/Predicting-eBay-Auction-Sales-with-Machine-Learning.aspx


\end{thebibliography}

\end{document}
